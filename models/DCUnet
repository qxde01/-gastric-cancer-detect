import os
import cv2
import numpy as np
from tensorflow import keras
import tensorflow as tf

# https://github.com/AngeLouCN/DC-UNet

def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):
    '''
    2D Convolutional layers

    Arguments:
        x {keras layer} -- input layer
        filters {int} -- number of filters
        num_row {int} -- number of rows in filters
        num_col {int} -- number of columns in filters

    Keyword Arguments:
        padding {str} -- mode of padding (default: {'same'})
        strides {tuple} -- stride of convolution operation (default: {(1, 1)})
        activation {str} -- activation function (default: {'relu'})
        name {str} -- name of the layer (default: {None})

    Returns:
        [keras layer] -- [output layer]
    '''

    x = keras.layers.Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)
    x = keras.layers.BatchNormalization(axis=3, scale=False)(x)

    if (activation == None):
        return x

    x = keras.layers.Activation(activation, name=name)(x)

    return x


def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):
    '''
    2D Transposed Convolutional layers

    Arguments:
        x {keras layer} -- input layer
        filters {int} -- number of filters
        num_row {int} -- number of rows in filters
        num_col {int} -- number of columns in filters

    Keyword Arguments:
        padding {str} -- mode of padding (default: {'same'})
        strides {tuple} -- stride of convolution operation (default: {(2, 2)})
        name {str} -- name of the layer (default: {None})

    Returns:
        [keras layer] -- [output layer]
    '''

    x = keras.layers.Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)
    x = keras.layers.BatchNormalization(axis=3, scale=False)(x)

    return x


def DCBlock(U, inp, alpha=1.67):
    '''
    DC Block

    Arguments:
        U {int} -- Number of filters in a corrsponding UNet stage
        inp {keras layer} -- input layer

    Returns:
        [keras layer] -- [output layer]
    '''

    W = alpha * U

    # shortcut = inp
    # shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +
    #                      int(W*0.5), 1, 1, activation=None, padding='same')

    conv3x3_1 = conv2d_bn(inp, int(W * 0.167), 3, 3, activation='relu', padding='same')

    conv5x5_1 = conv2d_bn(conv3x3_1, int(W * 0.333), 3, 3, activation='relu', padding='same')

    conv7x7_1 = conv2d_bn(conv5x5_1, int(W * 0.5), 3, 3,activation='relu', padding='same')

    out1 = keras.layers.concatenate([conv3x3_1, conv5x5_1, conv7x7_1], axis=3)
    out1 = keras.layers.BatchNormalization(axis=3)(out1)

    conv3x3_2 = conv2d_bn(inp, int(W * 0.167), 3, 3, activation='relu', padding='same')

    conv5x5_2 = conv2d_bn(conv3x3_2, int(W * 0.333), 3, 3,activation='relu', padding='same')

    conv7x7_2 = conv2d_bn(conv5x5_2, int(W * 0.5), 3, 3, activation='relu', padding='same')
    out2 = keras.layers.concatenate([conv3x3_2, conv5x5_2, conv7x7_2], axis=3)
    out2 = keras.layers.BatchNormalization(axis=3)(out2)

    out = keras.layers.add([out1, out2])
    out = keras.layers.Activation('relu')(out)
    out = keras.layers.BatchNormalization(axis=3)(out)

    return out


def ResPath(filters, length, inp):
    '''
    ResPath

    Arguments:
        filters {int} -- [description]
        length {int} -- length of ResPath
        inp {keras layer} -- input layer

    Returns:
        [keras layer] -- [output layer]
    '''

    shortcut = inp
    shortcut = conv2d_bn(shortcut, filters, 1, 1,activation=None, padding='same')

    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')

    out = keras.layers.add([shortcut, out])
    out = keras.layers.Activation('relu')(out)
    out = keras.layers.BatchNormalization(axis=3)(out)

    for i in range(length - 1):
        shortcut = out
        shortcut = conv2d_bn(shortcut, filters, 1, 1, activation=None, padding='same')
        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')
        out = keras.layers.add([shortcut, out])
        out = keras.layers.Activation('relu')(out)
        out = keras.layers.BatchNormalization(axis=3)(out)

    return out


def DCUNet(height, width, channels=3,filters=32):
    '''
    DC-UNet

    Arguments:
        height {int} -- height of image
        width {int} -- width of image
        n_channels {int} -- number of channels in image

    Returns:
        [keras model] -- MultiResUNet model
    '''

    inputs = keras.layers.Input((height, width, channels))

    dcblock1 = DCBlock(filters, inputs) #256X256
    pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(dcblock1)
    dcblock1 = ResPath(filters, 4, dcblock1) #256X256
    #print(dcblock1)

    dcblock2 = DCBlock(filters * 2, pool1) #128X128
    pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(dcblock2)
    dcblock2 = ResPath(filters * 2, 3, dcblock2) #128X128
    #print(dcblock2)
    dcblock3 = DCBlock(filters * 4, pool2)
    pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(dcblock3)
    dcblock3 = ResPath(filters * 4, 2, dcblock3)

    dcblock4 = DCBlock(filters * 8, pool3)#32X32
    pool4 = keras.layers.MaxPooling2D(pool_size=(2, 2))(dcblock4)
    dcblock4 = ResPath(filters * 8, 1, dcblock4)

    dcblock5 = DCBlock(filters * 16, pool4)#16X16
    #print(dcblock5 )

    up6 = keras.layers.concatenate([keras.layers.Conv2DTranspose(filters * 8, (2, 2), strides=(2, 2), padding='same')(dcblock5), dcblock4], axis=3) #32X32
    dcblock6 = DCBlock(filters * 8, up6)#32X32

    up7 = keras.layers.concatenate([keras.layers.Conv2DTranspose(filters * 4, (2, 2), strides=(2, 2), padding='same')(dcblock6), dcblock3], axis=3)#64X64
    dcblock7 = DCBlock(filters* 4, up7)#64X64

    up8 = keras.layers.concatenate([keras.layers.Conv2DTranspose(filters * 2, (2, 2), strides=(2, 2), padding='same')(dcblock7), dcblock2], axis=3)#128X128
    dcblock8 = DCBlock(filters * 2, up8)#128X128

    up9 = keras.layers.concatenate([keras.layers.Conv2DTranspose(filters, (2, 2), strides=( 2, 2), padding='same')(dcblock8), dcblock1], axis=3) #256X256
    dcblock9 = DCBlock(filters, up9)

    d1 = conv2d_bn(dcblock9, 1, 1, 1, activation='sigmoid',name='d1')
    d2 = keras.layers.UpSampling2D(size=(2, 2))(dcblock8)
    d2= conv2d_bn(d2, 1, 1, 1, activation='sigmoid', name='d2')

    d3 = keras.layers.UpSampling2D(size=(4, 4))(dcblock7)
    d3 = conv2d_bn(d3, 1, 1, 1, activation='sigmoid', name='d3')

    d4 = keras.layers.UpSampling2D(size=(8, 8))(dcblock6)
    d4 = conv2d_bn(d4, 1, 1, 1, activation='sigmoid', name='d4')

    d5 = keras.layers.UpSampling2D(size=(16, 16))(dcblock5)
    d5 = conv2d_bn(d5, 1, 1, 1, activation='sigmoid', name='d5')
    model = keras.models.Model(inputs=[inputs], outputs=[d1,d2,d3,d4,d5])

    return model

if __name__ == '__main__':
    '''256X256 filters=32
Total params: 10,071,536
Trainable params: 10,042,124
Non-trainable params: 29,412
filters=24
Total params: 5,671,167
Trainable params: 5,649,093
Non-trainable params: 22,074

    '''
    model=DCUNet(height=352, width=352, channels=3,filters=24)
    model.summary()
    keras.utils.plot_model(model,'DCUnet-352.png',show_shapes=True)
